{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "756ea10d-423f-4d7f-8d39-24f23c030a5f",
   "metadata": {},
   "source": [
    "# You Only Look Once (YOLO) Library\n",
    "\n",
    "You Only Look Once (YOLO) Library is used for image recognition tasks. The YOLOv8 Documentation can be found in teh following links.\n",
    "- https://docs.ultralytics.com/\n",
    "- https://github.com/ultralytics/ultralytics\n",
    "- https://docs.ultralytics.com/models/yolov8\n",
    "\n",
    "This library includes various models that have already been pretrained for different tasks (https://docs.ultralytics.com/models/yolov8/#key-features). These tasks include but is not limited to image detection, facial recognition, gender classification, object blurring, gender detection, counting objects, alerts, and using it with custom datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f5be46-c812-46fd-8858-a2a95c8db033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To install YOLOv8 install the ultralytics library by uncommenting and running the code line below. \n",
    "#pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657de6ec-5fca-433a-8e90-b9797465295d",
   "metadata": {},
   "source": [
    "# Python Library Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "101cc5fc-167c-4bd6-9bd1-4e1cbdf3bc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# HW Transformers to 0 fixes issue with USB Webcam Loading very slow in OpenCV\n",
    "os.environ[\"OPENCV_VIDEOIO_MSMF_ENABLE_HW_TRANSFORMS\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64ed50df-8eff-4958-9ed5-e331e26894aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2 as cv\n",
    "import math\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca79835-b702-4b71-adb3-dc9745b7171f",
   "metadata": {},
   "source": [
    "# YOLO Pre-Trained Models\n",
    "\n",
    "The YOLO libarry includes various sets of models that vary in size (e.g., yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt). These pretrained models have been trained using various pictures and typically the larger the model the better the accuracy. This pretrained models can be deployed to read a picture or read the frame of a video feed and recognize the objects that the model has been trained on.\n",
    "- https://docs.ultralytics.com/models/yolov8/#supported-tasks-and-modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c6d439b-f9a6-4867-91c0-10b2f27c7647",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('./input_data/yolov8n.pt') # Downloads (if does not exist) or accesses pre-trained model yolov8.pt into specified directory. \n",
    "\n",
    "#model = YOLO('./output_data/yolov8n_custom_2-PPE-COLAB-3epochs.pt') # Custom Dataset model trained in later steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ca5871-1d64-40e2-a2bb-0e6a315f6967",
   "metadata": {},
   "source": [
    "The model.names include the categories of images that the YOLOv8 model loaded above was trained to recognize. The list includes a total of 80 classes including but not limited to persons, vehicles, animals, fruits, kitchen appliances and various other objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64e47734-418a-4df0-aa77-8e9ee1ae866c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"
     ]
    }
   ],
   "source": [
    "print(model.names) # Prints classes within the Pre-Trained Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34515611-0707-49ea-8f10-0d8d6b8b081a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79])\n"
     ]
    }
   ],
   "source": [
    "print(model.names.keys()) # Prints keys within the Pre-Trained Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bf63837-4fd9-40e7-8fdd-e2c971a7e29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person',\n",
       " 'bicycle',\n",
       " 'car',\n",
       " 'motorcycle',\n",
       " 'airplane',\n",
       " 'bus',\n",
       " 'train',\n",
       " 'truck',\n",
       " 'boat',\n",
       " 'traffic light',\n",
       " 'fire hydrant',\n",
       " 'stop sign',\n",
       " 'parking meter',\n",
       " 'bench',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'sheep',\n",
       " 'cow',\n",
       " 'elephant',\n",
       " 'bear',\n",
       " 'zebra',\n",
       " 'giraffe',\n",
       " 'backpack',\n",
       " 'umbrella',\n",
       " 'handbag',\n",
       " 'tie',\n",
       " 'suitcase',\n",
       " 'frisbee',\n",
       " 'skis',\n",
       " 'snowboard',\n",
       " 'sports ball',\n",
       " 'kite',\n",
       " 'baseball bat',\n",
       " 'baseball glove',\n",
       " 'skateboard',\n",
       " 'surfboard',\n",
       " 'tennis racket',\n",
       " 'bottle',\n",
       " 'wine glass',\n",
       " 'cup',\n",
       " 'fork',\n",
       " 'knife',\n",
       " 'spoon',\n",
       " 'bowl',\n",
       " 'banana',\n",
       " 'apple',\n",
       " 'sandwich',\n",
       " 'orange',\n",
       " 'broccoli',\n",
       " 'carrot',\n",
       " 'hot dog',\n",
       " 'pizza',\n",
       " 'donut',\n",
       " 'cake',\n",
       " 'chair',\n",
       " 'couch',\n",
       " 'potted plant',\n",
       " 'bed',\n",
       " 'dining table',\n",
       " 'toilet',\n",
       " 'tv',\n",
       " 'laptop',\n",
       " 'mouse',\n",
       " 'remote',\n",
       " 'keyboard',\n",
       " 'cell phone',\n",
       " 'microwave',\n",
       " 'oven',\n",
       " 'toaster',\n",
       " 'sink',\n",
       " 'refrigerator',\n",
       " 'book',\n",
       " 'clock',\n",
       " 'vase',\n",
       " 'scissors',\n",
       " 'teddy bear',\n",
       " 'hair drier',\n",
       " 'toothbrush']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To select only specific classes modify this cell. \n",
    "keys_to_select = model.names.keys() # Selects all keys\n",
    "classes_selected = [] # Starting master list for selected classes.\n",
    "\n",
    "for key in keys_to_select: # Iterates through keys to extract classes as a list.\n",
    "    if key in model.names:\n",
    "        classes_selected.append(model.names[key]) #Appends classes to master list of selected class.\n",
    "\n",
    "classes_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e567e1-38f9-43d6-9cc0-b625efaa9468",
   "metadata": {},
   "source": [
    "### Image Recognition: In Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71f28b9f-90c4-43cd-906c-0451518b5970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WebCam input with Stop button\n",
    "stopButton = widgets.ToggleButton(value = False,\n",
    "                                  description = 'Stop',\n",
    "                                  disabled = False,\n",
    "                                  button_style= 'danger',\n",
    "                                  tooltip = 'Description',\n",
    "                                  icon = 'square' # (FontAwesome names without the `fa-` prefix)\n",
    "                                 )\n",
    "\n",
    "# Display function\n",
    "def view(button):\n",
    "    capture = cv.VideoCapture(1) # Video capture object. Camera 0 is the integrated camera while 1 is USB Camera.\n",
    "    # Frame Width/Height can be commented out. Common resolutions: 1920x1080, 1600x900, 1280x800, 640x480.\n",
    "    capture.set(cv.CAP_PROP_FRAME_WIDTH, 1360) \n",
    "    capture.set(cv.CAP_PROP_FRAME_HEIGHT, 960)\n",
    "    \n",
    "    # To save video as .avi file in the specified directory. May crash the application\n",
    "    #frame_width = int(capture.get(3)) # Gets frame width from cv.VideoCapture\n",
    "    #frame_height = int(capture.get(4))  # Gets frame height from cv.VideoCapture\n",
    "    #out = cv.VideoWriter('.output_data/video_output.avi', cv.VideoWriter_fourcc('M', 'J', 'P', 'G'), 10, (frame_width, frame_height))\n",
    "\n",
    "    # Specify Classes you need the model to predict if different from default.\n",
    "\n",
    "    display_handle = display(None, display_id=True)\n",
    "\n",
    "    #while True: # Both while statements seem to work.\n",
    "    while(capture.isOpened()):\n",
    "        _, frame = capture.read() # Reads and captures the image frame\n",
    "        frame = cv.flip(frame, 1) # Reverses image if webcam reverses\n",
    "        \n",
    "        results = model(source = frame,\n",
    "                        stream = True, # If True, can prevents out of memory issues\n",
    "                        verbose = False) # If True, prints information on inference speed, times, and other info\n",
    "\n",
    "        # Extracts each bounding box and displays it in the frame coordinates\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            for box in boxes:\n",
    "                x1,y1,x2,y2 = box.xyxy[0]\n",
    "                #print(x1, y1, x2, y2)\n",
    "                x1,y1,x2,y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                #print(x1,y1,x2,y2)\n",
    "                cv.rectangle(frame, (x1,y1), (x2,y2), (255,0,255),3)\n",
    "                #print(box.conf[0])\n",
    "                conf = math.ceil((box.conf[0]*100))/100\n",
    "                cls = int(box.cls[0])\n",
    "                class_name = classes_selected[cls]\n",
    "                label = f'{class_name}{conf}'\n",
    "                t_size = cv.getTextSize(label, 0, fontScale=1, thickness=2)[0]\n",
    "                #print(t_size)\n",
    "                c2 = x1 + t_size[0], y1 - t_size[1] - 3\n",
    "                cv.rectangle(frame, (x1,y1), c2, [255,0,255], -1, cv.LINE_AA)  # filled\n",
    "                cv.putText(frame, label, (x1,y1-2),0,1,[255,255,255], thickness=1, lineType=cv.LINE_AA)\n",
    "        #out.write(frame) # Writes video to file specified above\n",
    "        \n",
    "        _, frame = cv.imencode('.jpeg', frame) # Reads frame from buffer in memory\n",
    "        display_handle.update(Image(data=frame.tobytes())) # Uses the Jupyter Notebook Display to show in Notebook.\n",
    "        if stopButton.value == True: # Stops video instance using a button\n",
    "            capture.release()\n",
    "            cv.destroyAllWindows()\n",
    "            display_handle.update(None)\n",
    "            out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ecd9101-0171-4ac3-b93b-fe8299da798a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2c0af96ab64328b72a423f6d4824e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=False, button_style='danger', description='Stop', icon='square', tooltip='Description')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the view function. Note takes about 4 minutes to load video.\n",
    "display(stopButton)\n",
    "thread = threading.Thread(target = view, \n",
    "                          args = (stopButton,))\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19166f61-0f0f-4542-a8eb-9fe10cbbb89b",
   "metadata": {},
   "source": [
    "### Image Recognition: New Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91d1f09-dd65-41ac-866f-12f8aedd3483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note takes about 5 minutes to load image in new window.\n",
    "\n",
    "capture = cv.VideoCapture(1) # Video capture object. Camera 0 is the integrated camera while 1 is USB Camera.\n",
    "# Frame Width/Height can be commented out. Common resolutions: 1920x1080, 1600x900, 1280x800, 640x480.\n",
    "capture.set(cv.CAP_PROP_FRAME_WIDTH, 1360) \n",
    "capture.set(cv.CAP_PROP_FRAME_HEIGHT, 960)  \n",
    "\n",
    "# To save video as .avi file in the specified directory. May crash the application\n",
    "#frame_width = int(capture.get(3)) # Gets frame width from cv.VideoCapture\n",
    "#frame_height = int(capture.get(4))  # Gets frame height from cv.VideoCapture\n",
    "#out = cv.VideoWriter('.output_data/video_output.avi', cv.VideoWriter_fourcc('M', 'J', 'P', 'G'), 10, (frame_width, frame_height))\n",
    "\n",
    "while(capture.isOpened()):\n",
    "    _, frame = capture.read() # Reads and captures the image frame\n",
    "    frame = cv.flip(frame, 1) # Reverses image if webcam reverses\n",
    "    \n",
    "    results = model(source = frame,\n",
    "                    stream = True, # If True, can prevents out of memory issues\n",
    "                    verbose = False) # If True, prints information on inference speed, times, and other info\n",
    "    \n",
    "    # Extracts each bounding box and displays it in the frame coordinates\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            x1,y1,x2,y2 = box.xyxy[0]\n",
    "            #print(x1, y1, x2, y2)\n",
    "            x1,y1,x2,y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            #print(x1,y1,x2,y2)\n",
    "            cv.rectangle(frame, (x1,y1), (x2,y2), (255,0,255),3)\n",
    "            #print(box.conf[0])\n",
    "            conf = math.ceil((box.conf[0]*100))/100\n",
    "            cls = int(box.cls[0])\n",
    "            class_name = classes_selected[cls]\n",
    "            label = f'{class_name}{conf}'\n",
    "            t_size = cv.getTextSize(label, 0, fontScale=1, thickness=2)[0]\n",
    "            #print(t_size)\n",
    "            c2 = x1 + t_size[0], y1 - t_size[1] - 3\n",
    "            cv.rectangle(frame, (x1,y1), c2, [255,0,255], -1, cv.LINE_AA)  # filled\n",
    "            cv.putText(frame, label, (x1,y1-2),0, 1,[255,255,255], thickness = 1, lineType = cv.LINE_AA)\n",
    "    \n",
    "    #out.write(frame) # Writes video to file specified above\n",
    "    cv.imshow('Image Detection', frame) # Display in new window\n",
    "    \n",
    "    key = cv.waitKey(30) & 0xff # Reads keys every defined milliseconds to enter break below on key press\n",
    "    if key & 0xFF == ord('q') or key == 27 or 'x' == chr(key & 255): # To exit, press q, x, or ESC.\n",
    "        break\n",
    "        \n",
    "# Release the VideoCapture object\n",
    "capture.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e9a76-721e-4691-b045-738a8590515a",
   "metadata": {},
   "source": [
    "### Pre-Trained Model Notes\n",
    "- Accuracy will depend on the images that were used which we may or may not have access to via documentation.\n",
    "- Pre-trained models accuracy and size may vary significantly. Typically the higher the number of pciture used for training, the higher the accuracy, and the larger the model size.\n",
    "- Only useful in the defined model labels.\n",
    "\n",
    "What if we need to increase the capability of the model in a new label? \n",
    "We can start from scratch and train a new model with new set of images labeled for our specific use case.\n",
    "We could fine-tune a pre-trained model with a custom dataset to increase and expand its usability. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf53f42-1f47-40c5-9198-c3bf9fd318a7",
   "metadata": {},
   "source": [
    "# NOTEBOOK END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82692e15-7fbe-46b5-9e0c-db4ecdb9ca8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c6cb4-9441-4186-887f-656fe16b5c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d167c0-9fc7-4211-a375-d0e3bbe80473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
