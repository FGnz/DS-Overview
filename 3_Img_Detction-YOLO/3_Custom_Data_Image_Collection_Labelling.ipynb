{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dafbaf1e-cd8e-48a7-a380-26cba3d67939",
   "metadata": {},
   "source": [
    "# Imgage Detection with Custom Datasets\n",
    "\n",
    "In many cases we may need to identify, recognize, or predict other classes that are not part of a pretrained model. In those cases we may need to improve the model and train/fine-tune it by adding a custom dataset that includes such classes. The process to collect and develop an image dataset is long and ardous. This task includes having to collect images of our interested classes and having to annotate those images by creating bounding box and the class the image in the bounding box belongs to. To have an accurate custom images model the images collected during this process also need to be take into consideration and should represent the real use case scenarios including backgrounds, angles, distances, colors of the object, etc. \n",
    "\n",
    "In many cases there are organizations that collect or have collected images and we can leverage those efforts. In this example we will increase the capability of the model to detect images related to safety (e.g., hard hats, gloves, safety vests, safety shoes, face shields, etc.). An image collection with respective annotations and labels already exists within Roboflow application (refernce below). We will use this image collection to improve the YOLOV8n model and allow us to predict safety related classes.\n",
    "\n",
    "PPE Dataset from: https://universe.roboflow.com/objet-detect-yolov5/eep_detection-u9bbd/dataset/1\n",
    "@misc{                       eep_detection-u9bbd_dataset,\r\n",
    "                            title = { EEP_Detection Dataset },\r\n",
    "                            type = { Open Source Dataset },\r\n",
    "                            author = { Objet Detect YOLOV5 },\r\n",
    "                            howpublished = { \\url{ https://universe.roboflow.com/objet-detect-yolov5/eep_detection-u9bbd } },\r\n",
    "                            url = { https://universe.roboflow.com/objet-detect-yolov5/eep_detection-u9bbd },\r\n",
    "                            journal = { Roboflow Universe },\r\n",
    "                            publisher = { Roboflow },\r\n",
    "                            year = { 2022 },\r\n",
    "                            month = { jul },\r\n",
    "                            note = { visited on 2024-12-19 },\r\n",
    "                    The safety custom data from Roboflow         }\n",
    "\n",
    "is already annotated with a total of 3235 images (2264 for training, 647 for validation, and 324 f. There may be multiple object in an imageor testing). The dataset also has 14,341 annotations with images in a median resolution of 416x416. Labels and classes are as follows:\n",
    "- Class 0: 3296 images (i.e., hard hats, or helmets)\n",
    "- Class 8: 3098 images (i.e., gloves)\n",
    "- Class 9: 2985 images (i.e., safety shoes, or boots) \n",
    "- Class 3: 2635 images (i.e., safety vest, or jackets) \n",
    "- Class 4: 1526 images (i.e., mask, dust masks, or respirator)\n",
    "- Class 6: 784 images (i.e., safety glasses, or goggles)\n",
    "- Class 11: 150 images (i.e., facve process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1d51d3-d4a8-4761-b943-ffc2d8d04428",
   "metadata": {},
   "source": [
    "If we start from cratch andedevelop a model with custom images, anto collecanothe we would need totur woul to  to collectcomplestand annotate and edationd labeling. This procewhich is a intensive as resourceas it requires manually selecting bounding boxes for a spec within the imageific objected anotating such object with its corresponding label or class that we want to use in the model and imagen  Two tools that can be used for this are:\n",
    "- Roboflow:\n",
    "    - https://universe.roboflow.com/\n",
    "    - https://roboflow.com/\n",
    "- LabelImg:\n",
    "    - https://pypi.org/project/labelImg/\n",
    "    - https://blog.roboflow.com/labelimg/\n",
    "\n",
    "Other References:\n",
    "Documentation\n",
    "- https://docs.ultralytics.com/usage/cli/\n",
    "- https://docs.ultralytics.com/usage/python/\n",
    "\n",
    "Custom Dataset Models\n",
    "- https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/\n",
    "- https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/#13-prepare-dataset-for-yolov5\n",
    "- https://learnopencv.com/train-yolov8-on-custom-dataset/\n",
    "- https://learnopencv.com/train-yolov8-on-custom-dataset/#Train-YOLOv8-on-the-Custom-Pothole-Detection-Dataset\n",
    "\n",
    "Colab Notebooks\n",
    "- https://colab.research.google.com/github/s4ki3f/yolo/blob/main/notebooks/train-yolov8-object-classification-on-custom-dataset.ipynb#scrollTo=JaYAL8hDC20rve process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9ae21b-7a0c-4250-9187-ab3024addc24",
   "metadata": {},
   "source": [
    "# Fine-Tune YOLO Model on Custom Dataset  \n",
    "\n",
    "Using the custom dataset from Safety Images we can fine-tune a YOLO Model. This will allow us to train, test, validate, and run the model to predict images in the custom dataset. The next set of sections and Notebooks will discuss a few considerations as well as ways to downloading the data manually or directly into the Python environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf1c675-6d3d-469a-9d30-612f099a6567",
   "metadata": {},
   "source": [
    "# Potential Challenges and Issues\n",
    "When training a custom model using YOLO or other image library, you may encounter various issues which are discussed below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c64dd9-6573-4328-9c44-6ba2563dc6d6",
   "metadata": {},
   "source": [
    "#### Crashing\n",
    "There are multiple ways to run a YOLO custom datasets. This includes in a Jupyter Notebook, in the Command Line Interface (CLI), using a Python file, or in cloud environment (e.g., Google Colab). One option to avoid crashing issues and managing dependencies correctly is to use a virtual environment. Note that cloud environments deploy in virtual environments by default.\n",
    "\n",
    "Reference:\n",
    "- https://github.com/ultralytics/ultralytics/issues/8758"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aeeff4-09e7-487f-af8a-b42103d53715",
   "metadata": {},
   "source": [
    "#### Datasets Directory\n",
    "When first installed Ultralytics creates a global datasets directory to use for all datasets. The settings.yaml file generated by Ultralytics that assumes a global datasets directory for all your datasets. However, this is not optimal, and there is a better way to specify the data directories for your project. If the directory is updated this may cause an issue where the directory is not found. To resolve this issue there are two main options:\n",
    "- Specify the full path on the dataset .yaml file. \n",
    "- Change the datasets_dir parameter in the settings.yaml file to specify the correct data directory. Depending on your OS, you can find the settings.yaml file at ~/.config/Ultralytics/settings.yaml on Ubuntu and ~/Library/Application Support/Ultralytics/settings.yaml on Mac. Once you've located the settings.yaml file, replace the path in the datasets_dir parameter with the correct path to your project's data directory. You can also create a symlink/alias from ~/.ultralytics/datasets to your current project's dataset directory. \n",
    "    \n",
    "Reference:\n",
    "- https://github.com/ultralytics/ultralytics/issues/628"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e928ab0-fb60-4e02-bb19-1e184bb95f50",
   "metadata": {},
   "source": [
    "# Virtual Environment\n",
    "To avoid issues during training it is recommended to run the custom dataset model training/fine-tunning in a virtual environment. This allows us to have more control of the library dependencies. Virtual envioronments can be created locally in PC enviornment or by using a cloud environment (e.g., Google Colab).\n",
    "\n",
    "Note taht depending on the platform or approach utilized code directories may need to be updated.\n",
    "\n",
    "\n",
    "References:\n",
    "- https://www.geeksforgeeks.org/using-jupyter-notebook-in-virtual-environment/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ede3f83-0bfc-4265-a2e1-383779d068a9",
   "metadata": {},
   "source": [
    "# NOTEBOOK END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b24f7f-f2aa-49c8-941c-1eaac7528c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5add7ba6-c8a6-43fe-9ad2-eb440e2202e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f365c-4b75-41cf-b283-ab003a6efca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
